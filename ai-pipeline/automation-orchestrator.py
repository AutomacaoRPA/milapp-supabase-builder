#!/usr/bin/env python3
"""
MILAPP - Orquestrador de Automa√ß√£o IA-IA
Integra√ß√£o autom√°tica entre Lovable IA e Cursor IA
"""

import asyncio
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import aiohttp
import yaml

class AIIntegrationOrchestrator:
    def __init__(self, config_path: str = "ai-pipeline/config.yaml"):
        self.config = self.load_config(config_path)
        self.lovable_client = LovableAIClient(self.config['lovable'])
        self.cursor_client = CursorAIClient(self.config['cursor'])
        self.git_client = GitAutomationClient(self.config['git'])
        self.deployment_client = DeploymentClient(self.config['deployment'])
        
        # Estado do pipeline
        self.current_task = None
        self.task_history = []
        self.approval_queue = []
        
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def load_config(self, config_path: str) -> Dict:
        """Carrega configura√ß√£o do pipeline"""
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    
    async def start_automation_pipeline(self, task_description: str):
        """Inicia pipeline de automa√ß√£o IA-IA"""
        self.logger.info(f"üöÄ Iniciando pipeline para: {task_description}")
        
        # 1. An√°lise inicial com Cursor IA
        analysis = await self.cursor_client.analyze_requirements(task_description)
        
        # 2. Gera√ß√£o com Lovable IA
        generated_code = await self.lovable_client.generate_implementation(analysis)
        
        # 3. Revis√£o e refinamento com Cursor IA
        refined_code = await self.cursor_client.review_and_refine(generated_code)
        
        # 4. Testes autom√°ticos
        test_results = await self.run_automated_tests(refined_code)
        
        # 5. An√°lise de qualidade
        quality_report = await self.cursor_client.quality_analysis(refined_code)
        
        # 6. Preparar para aprova√ß√£o
        approval_package = self.prepare_approval_package(
            task_description, refined_code, test_results, quality_report
        )
        
        self.approval_queue.append(approval_package)
        
        self.logger.info("‚úÖ Pipeline conclu√≠do - Aguardando aprova√ß√£o")
        return approval_package
    
    async def run_automated_tests(self, code_changes: Dict) -> Dict:
        """Executa testes automatizados"""
        test_results = {
            'unit_tests': await self.run_unit_tests(code_changes),
            'integration_tests': await self.run_integration_tests(code_changes),
            'security_scan': await self.run_security_scan(code_changes),
            'performance_tests': await self.run_performance_tests(code_changes)
        }
        return test_results
    
    def prepare_approval_package(self, task: str, code: Dict, tests: Dict, quality: Dict) -> Dict:
        """Prepara pacote para aprova√ß√£o"""
        return {
            'id': f"task_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'task_description': task,
            'code_changes': code,
            'test_results': tests,
            'quality_report': quality,
            'summary': self.generate_summary(code, tests, quality),
            'risk_assessment': self.assess_risks(code, tests, quality),
            'created_at': datetime.now().isoformat(),
            'status': 'pending_approval'
        }
    
    async def approve_changes(self, task_id: str, approved: bool, comments: str = ""):
        """Aprova ou rejeita mudan√ßas"""
        task = next((t for t in self.approval_queue if t['id'] == task_id), None)
        if not task:
            raise ValueError(f"Task {task_id} n√£o encontrada")
        
        if approved:
            # Aplicar mudan√ßas
            await self.apply_changes(task['code_changes'])
            
            # Commit e push autom√°tico
            await self.git_client.commit_and_push(
                task['code_changes'], 
                f"feat: {task['task_description']} - Aprovado via IA-IA Pipeline"
            )
            
            # Deploy autom√°tico (se configurado)
            if self.config['deployment']['auto_deploy']:
                await self.deployment_client.deploy(task['code_changes'])
            
            self.logger.info(f"‚úÖ Mudan√ßas aprovadas e aplicadas: {task_id}")
        else:
            # Feedback para melhorias
            await self.process_rejection(task, comments)
            self.logger.info(f"‚ùå Mudan√ßas rejeitadas: {task_id}")
        
        task['status'] = 'approved' if approved else 'rejected'
        task['approval_comments'] = comments
        task['approved_at'] = datetime.now().isoformat()
    
    async def apply_changes(self, code_changes: Dict):
        """Aplica mudan√ßas no c√≥digo"""
        for file_path, content in code_changes['files'].items():
            file_path = Path(file_path)
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
    
    def generate_summary(self, code: Dict, tests: Dict, quality: Dict) -> str:
        """Gera resumo das mudan√ßas"""
        return f"""
üìã **Resumo das Mudan√ßas**
- Arquivos modificados: {len(code.get('files', {}))}
- Testes passaram: {tests.get('unit_tests', {}).get('passed', 0)}/{tests.get('unit_tests', {}).get('total', 0)}
- Qualidade: {quality.get('overall_score', 0)}/100
- Complexidade: {quality.get('complexity', 'Baixa')}
        """.strip()
    
    def assess_risks(self, code: Dict, tests: Dict, quality: Dict) -> Dict:
        """Avalia riscos das mudan√ßas"""
        risks = []
        
        if quality.get('overall_score', 0) < 70:
            risks.append("Qualidade do c√≥digo abaixo do padr√£o")
        
        if tests.get('security_scan', {}).get('vulnerabilities', 0) > 0:
            risks.append("Vulnerabilidades de seguran√ßa detectadas")
        
        if tests.get('unit_tests', {}).get('passed', 0) < tests.get('unit_tests', {}).get('total', 0):
            risks.append("Testes unit√°rios falharam")
        
        return {
            'risk_level': 'Alto' if len(risks) > 2 else 'M√©dio' if len(risks) > 0 else 'Baixo',
            'risks': risks,
            'recommendations': self.generate_recommendations(risks)
        }
    
    def generate_recommendations(self, risks: List[str]) -> List[str]:
        """Gera recomenda√ß√µes baseadas nos riscos"""
        recommendations = []
        
        if "Qualidade do c√≥digo abaixo do padr√£o" in risks:
            recommendations.append("Revisar padr√µes de c√≥digo antes de aprovar")
        
        if "Vulnerabilidades de seguran√ßa detectadas" in risks:
            recommendations.append("Corrigir vulnerabilidades antes do deploy")
        
        if "Testes unit√°rios falharam" in risks:
            recommendations.append("Corrigir testes antes de prosseguir")
        
        return recommendations

class LovableAIClient:
    """Cliente para integra√ß√£o com Lovable IA"""
    
    def __init__(self, config: Dict):
        self.api_key = config['api_key']
        self.base_url = config['base_url']
    
    async def generate_implementation(self, analysis: Dict) -> Dict:
        """Gera implementa√ß√£o baseada na an√°lise do Cursor IA"""
        prompt = self.build_lovable_prompt(analysis)
        
        # Simula√ß√£o da chamada para Lovable IA
        # Em produ√ß√£o, seria uma chamada real para a API
        return {
            'files': {
                'src/components/NewFeature.tsx': '// C√≥digo gerado pelo Lovable IA',
                'src/hooks/useNewFeature.ts': '// Hook gerado pelo Lovable IA',
                'tests/NewFeature.test.tsx': '// Testes gerados pelo Lovable IA'
            },
            'metadata': {
                'generated_by': 'Lovable IA',
                'prompt_used': prompt,
                'confidence_score': 0.85
            }
        }
    
    def build_lovable_prompt(self, analysis: Dict) -> str:
        """Constr√≥i prompt para Lovable IA baseado na an√°lise do Cursor"""
        return f"""
        Com base na an√°lise do Cursor IA, gere a implementa√ß√£o para:
        
        Contexto: {analysis.get('context', '')}
        Requisitos: {analysis.get('requirements', [])}
        Arquitetura: {analysis.get('architecture', {})}
        Padr√µes: {analysis.get('patterns', [])}
        
        Gere c√≥digo seguindo os padr√µes do projeto MILAPP.
        """

class CursorAIClient:
    """Cliente para integra√ß√£o com Cursor IA"""
    
    def __init__(self, config: Dict):
        self.api_key = config['api_key']
        self.base_url = config['base_url']
    
    async def analyze_requirements(self, task_description: str) -> Dict:
        """Analisa requisitos usando Cursor IA"""
        # Simula√ß√£o da an√°lise
        return {
            'context': 'An√°lise do contexto do projeto',
            'requirements': ['req1', 'req2', 'req3'],
            'architecture': {'frontend': 'React', 'backend': 'FastAPI'},
            'patterns': ['Component Pattern', 'Hook Pattern'],
            'dependencies': ['react', 'fastapi'],
            'estimated_complexity': 'M√©dia'
        }
    
    async def review_and_refine(self, generated_code: Dict) -> Dict:
        """Revisa e refina c√≥digo gerado pelo Lovable IA"""
        # Simula√ß√£o da revis√£o
        refined_code = generated_code.copy()
        refined_code['metadata']['refined_by'] = 'Cursor IA'
        refined_code['metadata']['improvements'] = [
            'Otimiza√ß√£o de performance',
            'Melhoria na tipagem TypeScript',
            'Adi√ß√£o de tratamento de erros'
        ]
        return refined_code
    
    async def quality_analysis(self, code: Dict) -> Dict:
        """An√°lise de qualidade do c√≥digo"""
        return {
            'overall_score': 85,
            'complexity': 'M√©dia',
            'maintainability': 'Alta',
            'test_coverage': 90,
            'security_score': 95,
            'performance_score': 88
        }

class GitAutomationClient:
    """Cliente para automa√ß√£o Git"""
    
    def __init__(self, config: Dict):
        self.repo_path = config['repo_path']
        self.branch = config['branch']
    
    async def commit_and_push(self, changes: Dict, message: str):
        """Commit e push autom√°tico"""
        # Implementa√ß√£o real seria com gitpython ou subprocess
        print(f"Git: Commitando mudan√ßas - {message}")

class DeploymentClient:
    """Cliente para deploy autom√°tico"""
    
    def __init__(self, config: Dict):
        self.deployment_url = config['url']
        self.api_key = config['api_key']
    
    async def deploy(self, changes: Dict):
        """Deploy autom√°tico"""
        # Implementa√ß√£o real seria com chamada para API de deploy
        print(f"Deploy: Aplicando mudan√ßas automaticamente")

# Configura√ß√£o do pipeline
CONFIG = {
    'lovable': {
        'api_key': 'your_lovable_api_key',
        'base_url': 'https://api.lovable.com'
    },
    'cursor': {
        'api_key': 'your_cursor_api_key',
        'base_url': 'https://api.cursor.com'
    },
    'git': {
        'repo_path': '.',
        'branch': 'main'
    },
    'deployment': {
        'auto_deploy': True,
        'url': 'https://deploy.milapp.com',
        'api_key': 'your_deploy_api_key'
    }
}

# Exemplo de uso
async def main():
    orchestrator = AIIntegrationOrchestrator()
    
    # Iniciar pipeline
    task = "Criar nova funcionalidade de dashboard de m√©tricas de automa√ß√£o"
    approval_package = await orchestrator.start_automation_pipeline(task)
    
    # Simular aprova√ß√£o
    await orchestrator.approve_changes(approval_package['id'], True, "Aprovado!")

if __name__ == "__main__":
    asyncio.run(main()) 